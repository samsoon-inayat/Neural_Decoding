{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of Naive Bayes decoder\n",
    "\n",
    "This example is similar to those shown in \"Examples_all_decoders.\"\n",
    "However, there is some preprocessing that is different for the Naive Bayes decoder, so we have made a separate notebook.\n",
    "\n",
    "In this example notebook, we:\n",
    "1. Import the necessary packages\n",
    "2. Load a data file (spike trains and outputs we are predicting)\n",
    "3. Preprocess the data\n",
    "4. Run the decoders and print the goodness of fit\n",
    "5. Plot example decoded outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Packages\n",
    "\n",
    "Below, we import both standard packages, and functions from the accompanying .py files\n",
    "Note that you may need to specify the path below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#Import standard packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy import io\n",
    "from scipy import stats\n",
    "import sys\n",
    "import pickle\n",
    "import h5py\n",
    "\n",
    "\n",
    "# If you would prefer to load the '.h5' example file rather than the '.pickle' example file. You need the deepdish package\n",
    "# import deepdish as dd \n",
    "\n",
    "#Import metrics\n",
    "from Neural_Decoding.metrics import get_R2\n",
    "from Neural_Decoding.metrics import get_rho\n",
    "\n",
    "#Import decoder functions\n",
    "from Neural_Decoding.decoders import NaiveBayesDecoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data\n",
    "The data for this example can be downloaded at this [link](https://www.dropbox.com/sh/n4924ipcfjqc0t6/AACPWjxDKPEzQiXKUUFriFkJa?dl=0&preview=example_data_hc.pickle). \n",
    "\n",
    "The data that we load is in the format described below. We have another example script, \"neural_preprocessing.py\" that may be helpful towards putting the data in this format.\n",
    "\n",
    "Neural data should be a matrix of size \"number of time bins\" x \"number of neurons\", where each entry is the firing rate of a given neuron in a given time bin\n",
    "\n",
    "The output you are decoding should be a matrix of size \"number of time bins\" x \"number of features you are decoding\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samsoon.inayat\\Anaconda3\\envs\\pi2p\\lib\\site-packages\\ipykernel_launcher.py:19: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'h5py._hl.group.Group'>\n",
      "<class 'h5py._hl.dataset.Dataset'>\n",
      "<class 'h5py._hl.dataset.Dataset'>\n",
      "<class 'h5py._hl.dataset.Dataset'>\n",
      "<class 'h5py._hl.dataset.Dataset'>\n"
     ]
    }
   ],
   "source": [
    "folder='E:/Users/samsoon.inayat/OneDrive - University of Lethbridge/Data/Neural_Decoding/' #ENTER THE FOLDER THAT YOUR DATA IS IN\n",
    "folder='G:/OneDrives/OneDrive - University of Lethbridge/Data/Neural_Decoding/' #ENTER THE FOLDER THAT YOUR DATA IS IN\n",
    "\n",
    "# folder='/home/jglaser/Data/DecData/' \n",
    "# folder='/Users/jig289/Dropbox/Public/Decoding_Data/'\n",
    "\n",
    "\n",
    "with open(folder+'example_data_hc.pickle','rb') as f:\n",
    "    neural_data,pos_binned=pickle.load(f,encoding='latin1') #If using python 3\n",
    "# #     neural_data,pos_binned=pickle.load(f)\n",
    "    \n",
    "# # #If you would prefer to load the '.h5' example file rather than the '.pickle' example file.\n",
    "# # data=dd.io.load(folder+'example_data_hc.h5')\n",
    "# # neural_data=data['neural_data']\n",
    "# # pos_binned=data['pos_binned']\n",
    "\n",
    "filename = folder + 'NB_decoding.mat'\n",
    "arrays = {}\n",
    "fm = h5py.File(filename)\n",
    "for k, v in fm.items():\n",
    "    print(type(v))\n",
    "#     arrays[k] = np.array(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1b917026388>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "aXs_C = fm['aXs_C'][0][0]\n",
    "aXs_C1 = np.array(fm[fm[aXs_C][0][0]])\n",
    "\n",
    "# for ii in range(0,aXs_C1.shape[1]):\n",
    "#     aXs_C1[:,ii] = aXs_C1[:,ii]/4\n",
    "\n",
    "aYs_C = fm['aYs_C'][0][0]\n",
    "aYs_C1p = np.array(fm[fm[aYs_C][0][0]])\n",
    "aYs_C1 = np.zeros([aYs_C1p.shape[0],2])\n",
    "aYs_C1[:,0] = aYs_C1p[:,0]\n",
    "aYs_C1[:,1] = aYs_C1p[:,0]\n",
    "plt.plot(aXs_C1[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3A. User Inputs\n",
    "The user can define what time period to use spikes from (with respect to the output)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_before=4 #How many bins of neural data prior to the output are used for decoding\n",
    "bins_current=1 #Whether to use concurrent time bin of neural data\n",
    "bins_after=5 #How many bins of neural data after the output are used for decoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3B. Format Covariates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Format Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove neurons with too few spikes in HC dataset\n",
    "nd_sum=np.nansum(neural_data,axis=0) #Total number of spikes of each neuron\n",
    "rmv_nrn=np.where(nd_sum<100) #Find neurons who have less than 100 spikes total\n",
    "neural_data=np.delete(neural_data,rmv_nrn,1) #Remove those neurons\n",
    "X=neural_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Format Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#Set decoding output\n",
    "y=pos_binned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3C. More formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of bins to sum spikes over\n",
    "N=bins_before+bins_current+bins_after "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#Remove time bins with no output (y value)\n",
    "rmv_time=np.where(np.isnan(y[:,0]) | np.isnan(y[:,1]))\n",
    "X=np.delete(X,rmv_time,0)\n",
    "y=np.delete(y,rmv_time,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D. Split into training/testing/validation sets\n",
    "Note that parameters should be setting using a separate validation set. \n",
    "Then, the goodness of fit should be be tested on a testing set (separate from the training and validation sets)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set what part of data should be part of the training/testing/validation sets\n",
    "\n",
    "training_range=[0, 0.5]\n",
    "valid_range=[0.5,0.65]\n",
    "testing_range=[0.65, 0.8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data: For Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#Number of examples after taking into account bins removed for lag alignment\n",
    "num_examples=X.shape[0]\n",
    "\n",
    "#Note that each range has a buffer of\"bins_before\" bins at the beginning, and \"bins_after\" bins at the end\n",
    "#This makes it so that the different sets don't include overlapping neural data\n",
    "training_set=np.arange(np.int(np.round(training_range[0]*num_examples))+bins_before,np.int(np.round(training_range[1]*num_examples))-bins_after)\n",
    "testing_set=np.arange(np.int(np.round(testing_range[0]*num_examples))+bins_before,np.int(np.round(testing_range[1]*num_examples))-bins_after)\n",
    "valid_set=np.arange(np.int(np.round(valid_range[0]*num_examples))+bins_before,np.int(np.round(valid_range[1]*num_examples))-bins_after)\n",
    "\n",
    "#Get training data\n",
    "X_train=X[training_set,:]\n",
    "y_train=y[training_set,:]\n",
    "\n",
    "#Get testing data\n",
    "X_test=X[testing_set,:]\n",
    "y_test=y[testing_set,:]\n",
    "\n",
    "#Get validation data\n",
    "X_valid=X[valid_set,:]\n",
    "y_valid=y[valid_set,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine data across specified bins\n",
    "Get total number of spikes across \"bins_before\",\"bins_current\",and \"bins_after\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#Initialize matrices for neural data in Naive bayes format\n",
    "num_nrns=X_train.shape[1]\n",
    "X_b_train=np.empty([X_train.shape[0]-N+1,num_nrns])\n",
    "X_b_valid=np.empty([X_valid.shape[0]-N+1,num_nrns])\n",
    "X_b_test=np.empty([X_test.shape[0]-N+1,num_nrns])\n",
    "\n",
    "#Below assumes that bins_current=1 (otherwise alignment will be off by 1 between the spikes and outputs)\n",
    "\n",
    "#For all neurons, within all the bins being used, get the total number of spikes (sum across all those bins)\n",
    "#Do this for the training/validation/testing sets\n",
    "for i in range(num_nrns):\n",
    "    X_b_train[:,i]=N*np.convolve(X_train[:,i], np.ones((N,))/N, mode='valid') #Convolving w/ ones is a sum across those N bins\n",
    "    X_b_valid[:,i]=N*np.convolve(X_valid[:,i], np.ones((N,))/N, mode='valid')\n",
    "    X_b_test[:,i]=N*np.convolve(X_test[:,i], np.ones((N,))/N, mode='valid')\n",
    "\n",
    "#Make integer format\n",
    "X_b_train=X_b_train.astype(int)\n",
    "X_b_valid=X_b_valid.astype(int)\n",
    "X_b_test=X_b_test.astype(int)\n",
    "\n",
    "#Make y's aligned w/ X's\n",
    "#e.g. we have to remove the first y if we are using 1 bin before, and have to remove the last y if we are using 1 bin after\n",
    "if bins_before>0 and bins_after>0:\n",
    "    y_train=y_train[bins_before:-bins_after,:]\n",
    "    y_valid=y_valid[bins_before:-bins_after,:]\n",
    "    y_test=y_test[bins_before:-bins_after,:]\n",
    "    \n",
    "if bins_before>0 and bins_after==0:\n",
    "    y_train=y_train[bins_before:,:]\n",
    "    y_valid=y_valid[bins_before:,:]\n",
    "    y_test=y_test[bins_before:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of examples after taking into account bins removed for lag alignment\n",
    "num_examples=aXs_C1.shape[0]\n",
    "\n",
    "#Note that each range has a buffer of\"bins_before\" bins at the beginning, and \"bins_after\" bins at the end\n",
    "#This makes it so that the different sets don't include overlapping neural data\n",
    "training_set=np.arange(np.int(np.round(training_range[0]*num_examples))+bins_before,np.int(np.round(training_range[1]*num_examples))-bins_after)\n",
    "testing_set=np.arange(np.int(np.round(testing_range[0]*num_examples))+bins_before,np.int(np.round(testing_range[1]*num_examples))-bins_after)\n",
    "valid_set=np.arange(np.int(np.round(valid_range[0]*num_examples))+bins_before,np.int(np.round(valid_range[1]*num_examples))-bins_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_b_train=aXs_C1[training_set,:]\n",
    "X_b_valid=aXs_C1[testing_set,:]\n",
    "X_b_test=aXs_C1[valid_set,:]\n",
    "\n",
    "X_b_train=X_b_train.astype(int)\n",
    "X_b_valid=X_b_valid.astype(int)\n",
    "X_b_test=X_b_test.astype(int)\n",
    "\n",
    "\n",
    "\n",
    "y_train = aYs_C1[training_set,:]\n",
    "y_test = aYs_C1[testing_set,:]\n",
    "y_valid = aYs_C1[valid_set,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run Decoder\n",
    "Note that in this example, we are evaluating the model fit on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#Declare model\n",
    "\n",
    "#The parameter \"encoding_model\" can either be linear or quadratic, although additional encoding models could later be added.\n",
    "\n",
    "#The parameter \"res\" is the number of bins used (resolution) for decoding predictions\n",
    "#So if res=100, we create a 100 x 100 grid going from the minimum to maximum of the output variables (x and y positions)\n",
    "#The prediction the decoder makes will be a value on that grid \n",
    "\n",
    "model_nb=NaiveBayesDecoder(encoding_model='quadratic',res=100)\n",
    "\n",
    "#Fit model\n",
    "model_nb.fit(X_b_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get predictions\n",
    "y_test_predicted=model_nb.predict(X_b_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get predictions\n",
    "y_valid_predicted=model_nb.predict(X_b_valid,y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get metric of fit\n",
    "R2_nb=get_R2(y_valid,y_valid_predicted)\n",
    "print(R2_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make example plot\n",
    "plt.plot(y_valid[2000:2500,1])\n",
    "plt.plot(y_valid_predicted[2000:2500,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#Get metric of fit\n",
    "R2_nb=get_R2(y_valid,y_valid_predicted)\n",
    "print(R2_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#Make example plot\n",
    "plt.plot(y_valid[2000:2500,1])\n",
    "plt.plot(y_valid_predicted[2000:2500,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
